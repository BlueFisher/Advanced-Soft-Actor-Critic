default:
  base_config:
    env_type: GYM
    env_name: ToyStack-v0
    env_args:
      map_width: 3
      target_type_num: 3

    n_envs: 100

  reset_config:
    stack_len: 100
    stack_nesting: 1
    max_nesting_depth: 15
    block_gap: [3, 10]
    success_reward: 2.
    failure_reward: -1.
    max_episode_steps: 2000

  nn_config:
    rep:
      pe: ROPE
      gate: RESIDUAL

  sac_config:
    burn_in_step: 0
    n_step: 5
    seq_encoder: RNN

    target_d_alpha: 0.2 # Target discrete alpha ratio

    discrete_dqn_like: false
    discrete_dqn_epsilon: 0.01
    use_priority: true # Whether using PER importance ratio

    batch_size: 1024

    learning_rate: 0.0003 # Learning rate of all optimizers

    use_rnd: false

  oc_config:
    option_epsilon: 0.0 # Probability of switching options
    option_seq_encoder: null
    terminal_entropy: 0.01 # Tending not to terminate >0, tending to terminate <0
    key_max_length: 100
    num_options: 3

rnn:
  base_config:
    name: rnn_{time}
  sac_config:
    burn_in_step: 12
    nn: nn_rnn
    seq_encoder: RNN

attn:
  base_config:
    name: attn_{time}
  sac_config:
    burn_in_step: 12
    nn: nn_attn
    seq_encoder: ATTN

oc_rnn:
  inherited: rnn
  base_config:
    name: oc_rnn_{time}

oc_attn:
  inherited: attn
  base_config:
    name: oc_attn_{time}

oc_dilated_rnn:
  inherited: oc_rnn
  base_config:
    name: oc_dilated_rnn_{time}
  oc_config:
    use_dilation: true

oc_dilated_attn:
  inherited: oc_attn
  base_config:
    name: oc_dilated_attn_{time}
  sac_config:
    nn: nn_dilated_attn
    burn_in_step: 0
  oc_config:
    use_dilation: true
