base_config:
  build_path: 
    win32: path_win32
    linux: path_linux
  build_port: 7000
  scene: scene

  name: "{time}"
  sac: sac
  # update policy variables each "update_policy_variables_per_step" 
  # or get action from learner each step
  update_policy_mode: true 
  update_policy_variables_per_step: -1
  # for actor, the number of transitions sent to replay
  add_trans_batch: 56
  max_step: -1
  reset_on_iteration: true
  
  burn_in_step: 0
  n_step: 1
  stagger: 1
  use_rnn: false
  use_prediction: true
  
net_config:
  replay_host: 127.0.0.1
  replay_port: 61000
  learner_host: 127.0.0.1
  learner_port: 61001

reset_config:
  copy: 1

replay_config:
  batch_size: 256
  capacity: 1000000
  alpha: 0.9
  use_mongodb: false

sac_config:
  seed: null
  save_model_per_step: 5000
  write_summary_per_step: 20
  tau: 0.005
  update_target_per_step: 1
  init_log_alpha: -2.3
  use_auto_alpha: true
  lr: 0.0003
  gamma: 0.99
  _lambda: 1.0