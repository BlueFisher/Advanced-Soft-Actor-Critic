base_config:
  env_type: UNITY # UNITY, GYM
  scene: scene

  # only for Unity Environments
  build_path: 
    win32: path_win32
    linux: path_linux
  build_port: 7000
  
  # only for Gym Enviroments
  build_path: GymEnv
  
  name: "{time}"
  sac: sac
  # update policy variables each "update_policy_variables_per_step" 
  # or get action from learner each step
  update_policy_mode: true
  # -1 for policy variables being updated each iteration
  update_policy_variables_per_step: -1
  max_step: -1
  save_model_per_iter: 10
  reset_on_iteration: true
  
net_config:
  replay_host: 127.0.0.1
  replay_port: 61000
  learner_host: 127.0.0.1
  learner_port: 61001

reset_config:
  copy: 1

replay_config:
  batch_size: 256
  capacity: 1000000
  alpha: 0.9
  use_mongodb: false

sac_config:
  seed: null
  write_summary_per_step: 20

  burn_in_step: 0
  n_step: 1
  use_rnn: false

  tau: 0.005
  update_target_per_step: 1
  init_log_alpha: -2.3
  use_auto_alpha: true
  q_lr: 0.0003
  policy_lr: 0.0003
  alpha_lr: 0.0003
  rnn_lr: 0.0003
  gamma: 0.99
  _lambda: 1.0
  use_prediction: false
  use_reward_normalization: false